{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:06:43.217098Z",
     "iopub.status.busy": "2024-10-03T16:06:43.216437Z",
     "iopub.status.idle": "2024-10-03T16:06:43.803759Z",
     "shell.execute_reply": "2024-10-03T16:06:43.802504Z",
     "shell.execute_reply.started": "2024-10-03T16:06:43.217060Z"
    },
    "id": "BFCkC-ztBbau",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:13:48.521073Z",
     "iopub.status.busy": "2024-10-03T16:13:48.520597Z",
     "iopub.status.idle": "2024-10-03T16:14:58.573222Z",
     "shell.execute_reply": "2024-10-03T16:14:58.572024Z",
     "shell.execute_reply.started": "2024-10-03T16:13:48.521035Z"
    },
    "id": "D2L41bqYBbav",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install trl wandb accelerate bitsandbytes evaluate\n",
    "!pip install torch==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OqsqLW0Bbav"
   },
   "source": [
    "## Auxiliary method\n",
    "Particolarmente importante è la funzione di formattazione *formatting_func_alt* che permette di realizzare la formattazione del dataset in maniera opportuna secondo ciò che è ripostato nel datast _link_. \\\n",
    "Il dataset (estratto dal sito https://www.jefit.com/routines) è in formato JSON ed è composto da coppie <Question,Answer> dove la prima è una stringa e la seconda un oggetto routine composto da titolo e lista degli allenamenti. Gli allenamenti sono delle tabelle composte da cinque feature <Esercizio,Reps,Sets,Rest,Interval> dove l'esercizio consiste in un oggetto caratterizzato da un nome e un gruppo muscolare target. \\\n",
    "L'output della formatting_func_alt consiste in una stringa formata da tanti elementi tante quante sono le righe nelle tabelle e hanno la forma \\\n",
    "{'i',Excercise:'Nome Esercizio',Reps:'# ripetizioni',Sets:'# set', Interval:'durata esercizio se prevista', Rest:'Durata della pausa finito l'esercizio', Day:'giorno di riferimento'} \\\n",
    "Da notare che l'indice *i* è univoco per ogni riga e che il nome corrisponde al solo nome dell'esercizio (viene eliminata l'informazione sul gruppo muscolare di riferimento). \\\n",
    "Da notare che la domanda è invece ottenuta combinando la domanda originale del dataset con il nome della routine nella ground truth per differenziare maggiormente gli esempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:08:03.223241Z",
     "iopub.status.busy": "2024-10-03T16:08:03.222909Z",
     "iopub.status.idle": "2024-10-03T16:08:03.238946Z",
     "shell.execute_reply": "2024-10-03T16:08:03.238043Z",
     "shell.execute_reply.started": "2024-10-03T16:08:03.223207Z"
    },
    "id": "LAFEd9IdBbaw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# metodo che effettua la formattazione delle coppie (Question,Answer) del dataset originale andando a creare una coppia di messaggi associati ad una domanda ottenuta come\n",
    "# concatenazione della Question originale e del nome del piano contenuto in Answer e ad una risposta che consiste in una versione serializzata della tabella originale.\n",
    "def formatting_func_alt(example):\n",
    "    answer = example['Answer']['Routine']\n",
    "    name = example['Answer']['Plan Name']\n",
    "    name = name.replace('- JEFIT','')\n",
    "    question = f'{example[\"Question\"]} {name}'\n",
    "    answ=[]\n",
    "    d=1\n",
    "    c=0\n",
    "    for routine in answer:\n",
    "        for excercise in routine:\n",
    "            tmp = excercise['Exercise']['Name']\n",
    "            excercise['Day']=d\n",
    "            excercise['Exercise']=tmp\n",
    "            tmp = {c:excercise}\n",
    "            c+=1\n",
    "            answ.append(tmp)\n",
    "        d+=1\n",
    "    ris = [{\"role\":\"user\",\"content\": question},{\"role\":\"assistant\",\"content\": answ}]\n",
    "    return ris\n",
    "\n",
    "# applica ad un esempio del dataset la formattazione e la trasformazione in prompt nella forma richiesta da mistral78 instruct e successivamente la tokenizza\n",
    "def generate_and_tokenize_prompt(prompt,max_length =  2048):\n",
    "    pairs = tokenizer.apply_chat_template(\n",
    "        formatting_func_alt(prompt),\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False)\n",
    "\n",
    "    result = tokenizer(\n",
    "        pairs,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "# metodo ausiliario per il conteggio del numero di parametri addestrabbili del modello\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTE6Psp9Bbaw"
   },
   "source": [
    "# Loading dataset\n",
    "Osservazione si è lasciata la porzione finale del dataset come validation set per ogni esecuzione di addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-03T16:08:03.241578Z",
     "iopub.status.busy": "2024-10-03T16:08:03.241295Z",
     "iopub.status.idle": "2024-10-03T16:08:07.654711Z",
     "shell.execute_reply": "2024-10-03T16:08:07.653923Z",
     "shell.execute_reply.started": "2024-10-03T16:08:03.241547Z"
    },
    "id": "eqBy3smjBbaw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='/kaggle/input/bb-routines/dataset.json', split='train[25%:30%]')\n",
    "eval_dataset = load_dataset('json', data_files='/kaggle/input/bb-routines/dataset.json', split='train[-1%:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:08:07.656025Z",
     "iopub.status.busy": "2024-10-03T16:08:07.655738Z",
     "iopub.status.idle": "2024-10-03T16:08:07.661108Z",
     "shell.execute_reply": "2024-10-03T16:08:07.659901Z",
     "shell.execute_reply.started": "2024-10-03T16:08:07.655994Z"
    },
    "id": "RNx2-0ERBbax",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(eval_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVFYuLvhBbax"
   },
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:08:07.662560Z",
     "iopub.status.busy": "2024-10-03T16:08:07.662253Z",
     "iopub.status.idle": "2024-10-03T16:09:51.602069Z",
     "shell.execute_reply": "2024-10-03T16:09:51.601279Z",
     "shell.execute_reply.started": "2024-10-03T16:08:07.662527Z"
    },
    "id": "Uc8YTbh4Bbax",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftConfig,PeftModel\n",
    "\n",
    "model_id = \"fabritmp/gym_mistral_finetune\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(model_id)\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             quantization_config=quant_config,\n",
    "                                             device_map=\"auto\",\n",
    "                                             low_cpu_mem_usage=True)\n",
    "\n",
    "model = PeftModel.from_pretrained(model,model_id,is_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVLRLUJnBbax"
   },
   "source": [
    "# Tokenizzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:09:51.603729Z",
     "iopub.status.busy": "2024-10-03T16:09:51.603222Z",
     "iopub.status.idle": "2024-10-03T16:09:53.127587Z",
     "shell.execute_reply": "2024-10-03T16:09:53.126684Z",
     "shell.execute_reply.started": "2024-10-03T16:09:51.603694Z"
    },
    "id": "W_2ekMz5Bbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:09:53.129208Z",
     "iopub.status.busy": "2024-10-03T16:09:53.128707Z",
     "iopub.status.idle": "2024-10-03T16:09:55.704276Z",
     "shell.execute_reply": "2024-10-03T16:09:55.702933Z",
     "shell.execute_reply.started": "2024-10-03T16:09:53.129174Z"
    },
    "id": "5_OBjyhvBbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:09:55.706042Z",
     "iopub.status.busy": "2024-10-03T16:09:55.705699Z",
     "iopub.status.idle": "2024-10-03T16:09:57.680527Z",
     "shell.execute_reply": "2024-10-03T16:09:57.679580Z",
     "shell.execute_reply.started": "2024-10-03T16:09:55.706006Z"
    },
    "id": "r6ME91UjBbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWyw4RJuBbay"
   },
   "source": [
    "# Weight download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clono i pesi del modello addestrato nella sessione precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:09:57.684317Z",
     "iopub.status.busy": "2024-10-03T16:09:57.683999Z",
     "iopub.status.idle": "2024-10-03T16:10:11.177726Z",
     "shell.execute_reply": "2024-10-03T16:10:11.176506Z",
     "shell.execute_reply.started": "2024-10-03T16:09:57.684283Z"
    },
    "id": "USqoEinGBbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/fabritmp/gym_mistral_finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12DKuNIpBbay"
   },
   "source": [
    "# Training\n",
    "Attenzione: eseguendo il codice così come si sovrascrivono i pesi memorizzati nella repo huggingface finito il training del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:10:11.179679Z",
     "iopub.status.busy": "2024-10-03T16:10:11.179299Z",
     "iopub.status.idle": "2024-10-03T16:10:14.200991Z",
     "shell.execute_reply": "2024-10-03T16:10:14.199921Z",
     "shell.execute_reply.started": "2024-10-03T16:10:11.179645Z"
    },
    "id": "XzEbIVgQBbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"your_key_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:14:58.576242Z",
     "iopub.status.busy": "2024-10-03T16:14:58.575764Z",
     "iopub.status.idle": "2024-10-03T16:15:14.062812Z",
     "shell.execute_reply": "2024-10-03T16:15:14.062040Z",
     "shell.execute_reply.started": "2024-10-03T16:14:58.576195Z"
    },
    "id": "LBoi0svEBbay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"bleu\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T16:22:06.089612Z",
     "iopub.status.busy": "2024-10-03T16:22:06.087947Z"
    },
    "id": "UMdM1igSBbaz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name # path output locale dei checkpoint del modello\n",
    "\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        resume_from_checkpoint=\"/kaggle/working/gym_mistral_finetune/last-checkpoint\",\n",
    "        per_device_train_batch_size=6,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=105,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay= 1e-2,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        adam_epsilon=1e-8,\n",
    "        logging_steps=15,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=105,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=15,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=\"mistral_gym_training_7\",\n",
    "        max_grad_norm=1.5,\n",
    "        hub_strategy=\"checkpoint\",\n",
    "        hub_model_id=\"fabritmp/gym_mistral_finetune\", #nome repository huggingface\n",
    "        hub_token=\"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\",\n",
    "        push_to_hub= True\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    peft_config=config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing= False,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjiJpPuZBbaz"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-03T16:10:14.645231Z",
     "iopub.status.idle": "2024-10-03T16:10:14.645738Z",
     "shell.execute_reply": "2024-10-03T16:10:14.645512Z",
     "shell.execute_reply.started": "2024-10-03T16:10:14.645474Z"
    },
    "id": "1zhCq88iBbaz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"fabritmp/gym_mistral_finetune\"\n",
    "config = PeftConfig.from_pretrained(model_id)\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-03T16:10:14.647186Z",
     "iopub.status.idle": "2024-10-03T16:10:14.647703Z",
     "shell.execute_reply": "2024-10-03T16:10:14.647454Z",
     "shell.execute_reply.started": "2024-10-03T16:10:14.647429Z"
    },
    "id": "9UJqei0BBbaz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-03T16:10:14.649211Z",
     "iopub.status.idle": "2024-10-03T16:10:14.650287Z",
     "shell.execute_reply": "2024-10-03T16:10:14.650056Z",
     "shell.execute_reply.started": "2024-10-03T16:10:14.650030Z"
    },
    "id": "bRTgk0OpBbaz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(generate_response(\"Can you make a 3 days a week beginner level workout?\", model))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5618402,
     "sourceId": 9282174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5568354,
     "sourceId": 9340251,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
